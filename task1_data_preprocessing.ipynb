{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data for Task 1\n",
    "## Import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all tables onto dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_1 = pd.read_csv(\"data/phase1_training/20min_avg_travel_time_training_phase1.csv\")\n",
    "train_t_2 = pd.read_csv(\"data/phase1_training/20min_avg_volume_training_phase1.csv\")\n",
    "train_t_3 = pd.read_csv(\"data/road/links_table3.csv\")\n",
    "train_t_4 = pd.read_csv(\"data/road/routes_table 4.csv\")\n",
    "train_t_5 = pd.read_csv(\"data/phase1_training/trajectories_training_phase1_table5.csv\")\n",
    "train_t_6 = pd.read_csv(\"data/phase1_training/volume_training_phase1_table6.csv\")\n",
    "train_t_7 = pd.read_csv(\"data/weather/weather_July_01_Oct_17_table7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_final = pd.read_csv(\"data/submission_sample/submission_sample_travelTime.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t_1 = pd.read_csv(\"data/phase1_test/20min_avg_travel_time_test_phase1.csv\")\n",
    "test_t_2 = pd.read_csv(\"data/phase1_test/20min_avg_volume_test_phase1.csv\")\n",
    "test_t_5 = pd.read_csv(\"data/phase1_test/trajectories_test_phase1_table5.csv\")\n",
    "test_t_6 = pd.read_csv(\"data/phase1_test/volume_test_phase1_table6.csv\")\n",
    "test_t_7 = pd.read_csv(\"data/weather/weather_Oct_18_Oct_24_table7.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers from table 5 -- trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, row in train_t_5.iterrows():\n",
    "    if row['travel_time'] > 600:\n",
    "        last_value = train_t_5.loc[k-1,'travel_time']\n",
    "        next_value = train_t_5.loc[k+1,'travel_time']\n",
    "        if last_value < 600:\n",
    "            train_t_5.loc[k, 'travel_time'] = (last_value + next_value)/2.0\n",
    "        else:\n",
    "            train_t_5.loc[k, 'travel_time'] = last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, row in test_t_5.iterrows():\n",
    "    if row['travel_time'] > 600:\n",
    "        last_value = test_t_5.loc[k-1,'travel_time']\n",
    "        next_value = test_t_5.loc[k+1,'travel_time']\n",
    "        if last_value < 600:\n",
    "            test_t_5.loc[k, 'travel_time'] = (last_value + next_value)/2.0\n",
    "        else:\n",
    "            test_t_5.loc[k, 'travel_time'] = last_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping the travel time of individual into average travel time for every 20 mins time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25144, 4) (448, 4)\n"
     ]
    }
   ],
   "source": [
    "# processing training data -- table 5\n",
    "\n",
    "train_t_5['starting_time'] = pd.to_datetime(train_t_5['starting_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "train_t_5 = train_t_5.set_index(['starting_time'])\n",
    "\n",
    "train_t_5 = train_t_5.groupby([pd.Grouper(freq='20Min'), \n",
    "                               'intersection_id', \n",
    "                               'tollgate_id']).travel_time.mean().reset_index().rename(\n",
    "    columns={'travel_time':'average_travl_time'})\n",
    "\n",
    "# processing test data -- table 5\n",
    "\n",
    "test_t_5['starting_time'] = pd.to_datetime(test_t_5['starting_time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "test_t_5 = test_t_5.set_index(['starting_time'])\n",
    "\n",
    "test_t_5 = test_t_5.groupby([pd.Grouper(freq='20Min'), \n",
    "                             'intersection_id', \n",
    "                             'tollgate_id']).travel_time.mean().reset_index().rename(\n",
    "    columns={'travel_time':'average_travl_time'})\n",
    "\n",
    "print(train_t_5.shape, test_t_5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create unique pairs of all intersection and toll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_toll_intersections = []\n",
    "\n",
    "for j in range(sample_data_final.shape[0]):    \n",
    "    intersection=sample_data_final.loc[j]['intersection_id']\n",
    "    tollgate=sample_data_final.loc[j]['tollgate_id']\n",
    "    token = (intersection,tollgate)\n",
    "    if token not in all_toll_intersections:\n",
    "        all_toll_intersections.append(token)\n",
    "        \n",
    "sample_time = []\n",
    "sample_times = sample_data_final[(sample_data_final['tollgate_id']==1)&\n",
    "                                 (sample_data_final['intersection_id']=='B')]['time_window']\n",
    "\n",
    "for st in sample_times:\n",
    "    sample_time.append(pd.to_datetime(st.split(',')[0][1:], format=\"%Y-%m-%d %H:%M:%S\") - pd.DateOffset(hours=2))\n",
    "\n",
    "sample_time = pd.Series(sample_time).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method to replace missing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_time(test, tollgate, intersection, iteration, sample_time):\n",
    "    while iteration > 0:\n",
    "        try:\n",
    "            missing_time = test[(test['tollgate_id']==tollgate)& \n",
    "                                (test['starting_time'] == sample_time[iteration - 1])& \n",
    "                                (test['intersection_id']==intersection)]['average_travl_time']\n",
    "            \n",
    "            return missing_time.values[0]\n",
    "        except Exception as e:\n",
    "            iteration = iteration - 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace the missing time in table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for intersection, tollgate in all_toll_intersections:\n",
    "    test_toll_intersections = copy(test_t_5[(test_t_5['tollgate_id']==tollgate) & \n",
    "                                                       (test_t_5['intersection_id']==intersection) \n",
    "                                                     ].reset_index()) \n",
    "    \n",
    "    test_time= test_t_5[(test_t_5['tollgate_id']==tollgate) & \n",
    "                                   (test_t_5['intersection_id']==intersection)\n",
    "                                  ]['starting_time'].values\n",
    "    \n",
    "    test_toll_intersections.drop('index',axis=1,inplace=True)\n",
    "    test_toll_intersections = test_toll_intersections.loc[0]\n",
    "    \n",
    "    for k in range(len(sample_time)):\n",
    "        if sample_time[k] not in test_time: \n",
    "            test_toll_intersections['starting_time'] = sample_time[k]\n",
    "            test_toll_intersections['average_travl_time'] = replace_missing_time(test_t_5, \n",
    "                                                                                 tollgate, \n",
    "                                                                                 intersection,\n",
    "                                                                                 k, \n",
    "                                                                                 sample_time)\n",
    "            \n",
    "            test_t_5 = test_t_5.append(test_toll_intersections)\n",
    "            \n",
    "test_t_5 = test_t_5.reset_index()\n",
    "test_t_5.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_5 = train_t_5.append(test_t_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_5['lag1'] = train_t_5['average_travl_time'].shift(1)\n",
    "train_t_5['lag2'] = train_t_5['average_travl_time'].shift(2)\n",
    "train_t_5['lag3'] = train_t_5['average_travl_time'].shift(3)\n",
    "train_t_5['lag4'] = train_t_5['average_travl_time'].shift(4)\n",
    "train_t_5['lag5'] = train_t_5['average_travl_time'].shift(5)\n",
    "train_t_5['lag6'] = train_t_5['average_travl_time'].shift(6)\n",
    "train_t_5['lag7'] = train_t_5['average_travl_time'].shift(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a heat map of the table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(train_t_5.corr(), annot = True, fmt = \".2f\")\n",
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create another dataframe from table 5 with a date offset of 2 hours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t_5['starting_time'] = test_t_5['starting_time'] + pd.DateOffset(hours=2)\n",
    "test_t_5_dup = test_t_5\n",
    "test_t_5_dup.drop('average_travl_time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_time</th>\n",
       "      <th>intersection_id</th>\n",
       "      <th>tollgate_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-18 08:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-18 08:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-10-18 08:00:00</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-18 08:00:00</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-18 08:00:00</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        starting_time intersection_id  tollgate_id\n",
       "0 2016-10-18 08:00:00               A            2\n",
       "1 2016-10-18 08:00:00               A            3\n",
       "2 2016-10-18 08:00:00               B            1\n",
       "3 2016-10-18 08:00:00               B            3\n",
       "4 2016-10-18 08:00:00               C            1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_t_5_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 3)\n",
      "(25648, 11)\n"
     ]
    }
   ],
   "source": [
    "print(test_t_5_dup.shape)\n",
    "print(train_t_5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional info -- adding festival day's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese festival days\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start_date = datetime(2016, 9, 15)\n",
    "end_date = datetime(2016, 9, 17)\n",
    "holiday_range = pd.date_range(start_date, end_date)\n",
    "start_date2 = datetime(2016, 10, 1)\n",
    "end_date2 = datetime(2016, 10, 7)\n",
    "holiday_range= holiday_range.append(pd.date_range(start_date2, end_date2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Extra column with the name ch_holidays. If the date exists in between Holiday range,the value of \n",
    "#the column will be 1 or else 0\n",
    "\n",
    "def identify_holiday_dates(data, start_time):\n",
    "    day_of_the_week = pd.get_dummies(data[start_time].dt.weekday_name)\n",
    "    hr_of_the_day = pd.get_dummies(data[start_time].dt.hour, prefix='hour_')\n",
    "    minute= pd.get_dummies(data[start_time].dt.minute)\n",
    "    data = pd.concat([data, day_of_the_week, hr_of_the_day, minute], axis=1)\n",
    "    data['date'] = data[start_time].dt.date\n",
    "    data['date'] = data['date'].astype(str)\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "    data['hour'] = data[start_time].dt.hour.astype(int)\n",
    "    start_time_date = data[start_time].dt.date\n",
    "    \n",
    "    for k, row in data.iterrows():\n",
    "        data.loc[k,\"ch_holidays\"] = 0\n",
    "        if start_time_date.loc[k] in holiday_range: data.loc[k, \"ch_holidays\"] = 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_5 = identify_holiday_dates(train_t_5, \"starting_time\")\n",
    "test_t_5_dup = identify_holiday_dates(test_t_5_dup, \"starting_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_time</th>\n",
       "      <th>intersection_id</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>average_travl_time</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>...</th>\n",
       "      <th>hour__20</th>\n",
       "      <th>hour__21</th>\n",
       "      <th>hour__22</th>\n",
       "      <th>hour__23</th>\n",
       "      <th>0</th>\n",
       "      <th>20</th>\n",
       "      <th>40</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>ch_holidays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-19 00:00:00</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>70.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-19 00:20:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>58.05</td>\n",
       "      <td>70.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-07-19 00:20:00</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>79.76</td>\n",
       "      <td>58.05</td>\n",
       "      <td>70.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-19 00:20:00</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>148.79</td>\n",
       "      <td>79.76</td>\n",
       "      <td>58.05</td>\n",
       "      <td>70.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-07-19 00:40:00</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>137.98</td>\n",
       "      <td>148.79</td>\n",
       "      <td>79.76</td>\n",
       "      <td>58.05</td>\n",
       "      <td>70.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        starting_time intersection_id  tollgate_id  average_travl_time  \\\n",
       "0 2016-07-19 00:00:00               B            3               70.85   \n",
       "1 2016-07-19 00:20:00               A            2               58.05   \n",
       "2 2016-07-19 00:20:00               B            1               79.76   \n",
       "3 2016-07-19 00:20:00               B            3              148.79   \n",
       "4 2016-07-19 00:40:00               B            1              137.98   \n",
       "\n",
       "     lag1   lag2   lag3   lag4  lag5  lag6  ...  hour__20  hour__21  hour__22  \\\n",
       "0     NaN    NaN    NaN    NaN   NaN   NaN  ...         0         0         0   \n",
       "1   70.85    NaN    NaN    NaN   NaN   NaN  ...         0         0         0   \n",
       "2   58.05  70.85    NaN    NaN   NaN   NaN  ...         0         0         0   \n",
       "3   79.76  58.05  70.85    NaN   NaN   NaN  ...         0         0         0   \n",
       "4  148.79  79.76  58.05  70.85   NaN   NaN  ...         0         0         0   \n",
       "\n",
       "   hour__23  0  20  40       date  hour  ch_holidays  \n",
       "0         0  1   0   0 2016-07-19     0          0.0  \n",
       "1         0  0   1   0 2016-07-19     0          0.0  \n",
       "2         0  0   1   0 2016-07-19     0          0.0  \n",
       "3         0  0   1   0 2016-07-19     0          0.0  \n",
       "4         0  0   0   1 2016-07-19     0          0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_t_5_dup.shape)\n",
    "train_t_5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding table 7 (weather data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and appending weather test data to weather train data\n",
    "\n",
    "train_t_7 = train_t_7.append(test_t_7).reset_index()\n",
    "train_t_7['date'] = pd.to_datetime(train_t_7['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove outlier from weather table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the outlier value of 99017 in wind_direction of weatherData by avg of previous and next value\n",
    "# 99017 is the only outlier\n",
    "\n",
    "for i, row in train_t_7.iterrows():\n",
    "    if row['wind_direction']== 999017.0:\n",
    "        previous_value = train_t_7.loc[i-1,'wind_direction']\n",
    "        next_value = train_t_7.loc[i+1,'wind_direction']\n",
    "        if next_value != 999017.0:\n",
    "            train_t_7.loc[i, 'wind_direction'] = (previous_value + next_value)/2.0\n",
    "        else:\n",
    "            train_t_7.loc[i, 'wind_direction'] = previous_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.4</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>26.4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.5</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>187.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>6</td>\n",
       "      <td>998.9</td>\n",
       "      <td>1003.7</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>31.7</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>9</td>\n",
       "      <td>998.7</td>\n",
       "      <td>1003.5</td>\n",
       "      <td>244.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>31.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>12</td>\n",
       "      <td>999.7</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       date  hour  pressure  sea_pressure  wind_direction  wind_speed  \\\n",
       "0      0 2016-07-01     0    1000.4        1005.3           225.0         2.1   \n",
       "1      1 2016-07-01     3    1000.5        1005.3           187.0         2.7   \n",
       "2      2 2016-07-01     6     998.9        1003.7           212.0         2.9   \n",
       "3      3 2016-07-01     9     998.7        1003.5           244.0         2.7   \n",
       "4      4 2016-07-01    12     999.7        1004.5           222.0         1.3   \n",
       "\n",
       "   temperature  rel_humidity  precipitation  \n",
       "0         26.4          94.0            0.0  \n",
       "1         29.0          76.0            0.0  \n",
       "2         31.7          67.0            0.0  \n",
       "3         31.6          59.0            0.0  \n",
       "4         29.9          68.0            0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25648, 48)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t_5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining table 5 with table 7 (trajectory data + weather data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn hour into 3 hour intervals and then combine with weather data\n",
    "\n",
    "def addWeatherData(df):\n",
    "    for i, row in df.iterrows():\n",
    "        if row['hour'] in [23,0,1]: df.loc[i, \"hour\"] = 0\n",
    "        elif row['hour'] in [2,3,4]: df.loc[i, \"hour\"] = 3 \n",
    "        elif row['hour'] in [5,6,7]: df.loc[i, \"hour\"] = 6         \n",
    "        elif row['hour'] in [8,9,10]: df.loc[i, \"hour\"] = 9         \n",
    "        elif row['hour'] in [11,12,13]: df.loc[i, \"hour\"] = 12         \n",
    "        elif row['hour'] in [14,15,16]: df.loc[i, \"hour\"] = 15         \n",
    "        elif row['hour'] in [17,18,19]: df.loc[i, \"hour\"] = 18         \n",
    "        elif row['hour'] in [20,21,22]: df.loc[i, \"hour\"] = 21\n",
    "    return pd.merge(df, train_t_7, on =['date', 'hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_5 = addWeatherData(train_t_5)\n",
    "test_t_5_dup = addWeatherData(test_t_5_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_time</th>\n",
       "      <th>intersection_id</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>average_travl_time</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>ch_holidays</th>\n",
       "      <th>index</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-19 00:00:00</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>70.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>999.7</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>31.8</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-19 00:20:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>58.05</td>\n",
       "      <td>70.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>999.7</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>31.8</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-07-19 00:20:00</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>79.76</td>\n",
       "      <td>58.05</td>\n",
       "      <td>70.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>999.7</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>31.8</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-19 00:20:00</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>148.79</td>\n",
       "      <td>79.76</td>\n",
       "      <td>58.05</td>\n",
       "      <td>70.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>999.7</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>31.8</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-07-19 00:40:00</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>137.98</td>\n",
       "      <td>148.79</td>\n",
       "      <td>79.76</td>\n",
       "      <td>58.05</td>\n",
       "      <td>70.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>999.7</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>31.8</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        starting_time intersection_id  tollgate_id  average_travl_time  \\\n",
       "0 2016-07-19 00:00:00               B            3               70.85   \n",
       "1 2016-07-19 00:20:00               A            2               58.05   \n",
       "2 2016-07-19 00:20:00               B            1               79.76   \n",
       "3 2016-07-19 00:20:00               B            3              148.79   \n",
       "4 2016-07-19 00:40:00               B            1              137.98   \n",
       "\n",
       "     lag1   lag2   lag3   lag4  lag5  lag6  ...  hour  ch_holidays  index  \\\n",
       "0     NaN    NaN    NaN    NaN   NaN   NaN  ...     6          0.0  146.0   \n",
       "1   70.85    NaN    NaN    NaN   NaN   NaN  ...     6          0.0  146.0   \n",
       "2   58.05  70.85    NaN    NaN   NaN   NaN  ...     6          0.0  146.0   \n",
       "3   79.76  58.05  70.85    NaN   NaN   NaN  ...     6          0.0  146.0   \n",
       "4  148.79  79.76  58.05  70.85   NaN   NaN  ...     6          0.0  146.0   \n",
       "\n",
       "   pressure  sea_pressure  wind_direction  wind_speed  temperature  \\\n",
       "0     999.7        1004.5           239.0         1.9         31.8   \n",
       "1     999.7        1004.5           239.0         1.9         31.8   \n",
       "2     999.7        1004.5           239.0         1.9         31.8   \n",
       "3     999.7        1004.5           239.0         1.9         31.8   \n",
       "4     999.7        1004.5           239.0         1.9         31.8   \n",
       "\n",
       "   rel_humidity  precipitation  \n",
       "0          64.0            0.0  \n",
       "1          64.0            0.0  \n",
       "2          64.0            0.0  \n",
       "3          64.0            0.0  \n",
       "4          64.0            0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25648, 54)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t_5 = train_t_5.drop(['hour','date'],axis=1)\n",
    "test_t_5_dup = test_t_5_dup.drop(['hour','date'],axis=1)\n",
    "train_t_5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "divison_row = []\n",
    "\n",
    "def divide(seq):\n",
    "    return seq.split(',')\n",
    "\n",
    "train_t_4.link_seq = train_t_4.link_seq.apply(divide)\n",
    "\n",
    "X = train_t_4.apply(lambda row: [divison_row.append([row['intersection_id'], row['tollgate_id'], link]) \n",
    "                         for link in row.link_seq], axis=1)\n",
    "\n",
    "table_headers = ['intersection_id', 'tollgate_id', 'link_id']\n",
    "train_t_4_new= pd.DataFrame(divison_row, columns=table_headers)\n",
    "train_t_4_new['link_id'] = train_t_4_new['link_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_3['cross_in'] = 0\n",
    "train_t_3['cross_out'] = 0\n",
    "\n",
    "for k, row in train_t_3.iterrows():\n",
    "    if ',' in str(row['out_top']):\n",
    "        train_t_3.loc[k, 'cross_out'] = 1\n",
    "    if ',' in str(row['in_top']):\n",
    "        train_t_3.loc[k, 'cross_in'] = 1\n",
    "        \n",
    "train_t_3['link_id'] = train_t_3['link_id'].astype(str)  \n",
    "train_t_4_new = pd.merge(train_t_4_new, train_t_3, on='link_id', how='left')\n",
    "train_t_4_new.drop(['in_top', 'out_top'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging table 4 with table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_incount= train_t_4_new[['intersection_id', 'tollgate_id', 'cross_in']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).cross_in.sum().reset_index().rename(columns={\n",
    "    'cross_in':'inlink_cross_count'})\n",
    "\n",
    "join_outcount = train_t_4_new[['intersection_id', 'tollgate_id', 'cross_out']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).cross_out.sum().reset_index().rename(columns={\n",
    "    'cross_out':'outlink_cross_count'})\n",
    "\n",
    "final = pd.merge(join_incount, join_outcount, on=['intersection_id', 'tollgate_id'], how='left')\n",
    "\n",
    "_len = train_t_4_new[['intersection_id', 'tollgate_id', 'length']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).length.sum().reset_index()\n",
    "\n",
    "final = pd.merge(final, _len, on=['intersection_id', 'tollgate_id'], how='left')\n",
    "\n",
    "link_count = train_t_4_new[['intersection_id', 'tollgate_id']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).size().reset_index().rename(columns={0:'link_count'})\n",
    "\n",
    "final = pd.merge(final, link_count, on=['intersection_id', 'tollgate_id'], how='left')\n",
    "\n",
    "lane1_length = train_t_4_new[train_t_4_new.lanes==1][['intersection_id', 'tollgate_id', 'length']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).length.sum().reset_index().rename(columns={'length':'lane1_length'})\n",
    "\n",
    "final = pd.merge(final, lane1_length, on=['intersection_id', 'tollgate_id'], how='left')\n",
    "\n",
    "lane1_count = train_t_4_new[train_t_4_new.lanes== 1][['intersection_id', 'tollgate_id']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).size().reset_index().rename(columns = {0:'lane1_count'})\n",
    "\n",
    "final = pd.merge(final, lane1_count, on =['intersection_id', 'tollgate_id'], how='left')\n",
    "\n",
    "lane2_length = train_t_4_new[train_t_4_new.lanes==2][['intersection_id', 'tollgate_id', 'length']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).length.sum().reset_index().rename(columns={'length':'lane2_length'})\n",
    "\n",
    "final = pd.merge(final, lane2_length, on=['intersection_id', 'tollgate_id'], how='left')\n",
    "\n",
    "lane2_count = train_t_4_new[train_t_4_new.lanes== 2][['intersection_id', 'tollgate_id']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).size().reset_index().rename(columns = {0:'lane2_count'})\n",
    "\n",
    "final = pd.merge(final, lane2_count, on =['intersection_id', 'tollgate_id'], how='left')\n",
    "\n",
    "lane3_length = train_t_4_new[train_t_4_new.lanes==3][['intersection_id', 'tollgate_id', 'length']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).length.sum().reset_index().rename(columns={'length':'lane3_length'})\n",
    "\n",
    "final = pd.merge(final, lane3_length, on=['intersection_id', 'tollgate_id'], how='left')\n",
    "\n",
    "lane3_count = train_t_4_new[train_t_4_new.lanes==3][['intersection_id', 'tollgate_id']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).size().reset_index().rename(columns = {0:'lane3_count'})\n",
    "\n",
    "final = pd.merge(final,lane3_count,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "\n",
    "lane4_length = train_t_4_new[train_t_4_new.lanes==4][['intersection_id', 'tollgate_id', 'length']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).length.sum().reset_index().rename(columns={'length':'lane4_length'})\n",
    "\n",
    "final = pd.merge(final, lane4_length, on=['intersection_id', 'tollgate_id'],how='left')\n",
    "\n",
    "lane4_count = train_t_4_new[train_t_4_new.lanes==4][['intersection_id', 'tollgate_id']].groupby([\n",
    "    'intersection_id', 'tollgate_id']).size().reset_index().rename(columns = {0:'lane4_count'})\n",
    "\n",
    "final = pd.merge(final,lane4_count,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "\n",
    "final.fillna(0, inplace=True)\n",
    "\n",
    "train_t_5 = pd.merge(train_t_5, final, on=['intersection_id', 'tollgate_id'], how='left')\n",
    "\n",
    "test_t_5_dup = pd.merge(test_t_5_dup, final, on=['intersection_id', 'tollgate_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting starting and end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_period(data, start_time, end_time):\n",
    "    st = data[start_time].apply(lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    et = data[end_time].apply(lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    data['time_window'] = '[' + st + ',' + et + ')'\n",
    "    \n",
    "    return data.drop([start_time, end_time], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t_5_dup['end'] = test_t_5_dup['starting_time'] + pd.DateOffset(minutes=20)\n",
    "train_t_5['end'] = train_t_5['starting_time'] + pd.DateOffset(minutes=20)\n",
    "test_t_5_dup = time_period(test_t_5_dup, 'starting_time', 'end')\n",
    "train_t_5 = time_period(train_t_5, 'starting_time', 'end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t_5_dup = test_t_5_dup.set_index(['intersection_id', 'tollgate_id', 'time_window'])\n",
    "train_t_5 = train_t_5.set_index(['intersection_id','tollgate_id','time_window'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25648, 63)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t_5_columns, train_t_5_columns = list(test_t_5_dup.columns.values), list(train_t_5.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_t5 =  [data for data in train_t_5_columns if data not in test_t_5_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in m_t5:\n",
    "    test_t_5_dup[label] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t_5_dup = test_t_5_dup[train_t_5_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the missing values with mean value in table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nullvalues(data):\n",
    "    return data.fillna(data.mean())\n",
    "\n",
    "test_t_5_dup = fill_nullvalues(test_t_5_dup)\n",
    "\n",
    "train_t_5 =fill_nullvalues(train_t_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 63) (25648, 63)\n"
     ]
    }
   ],
   "source": [
    "print(test_t_5_dup.shape, train_t_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t_5_dup.to_csv(\"data/preprocessing_data/task1_preprocess_test_data.csv\")\n",
    "train_t_5.to_csv(\"data/preprocessing_data/task1_preprocess_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['average_travl_time', 'lag1', 'lag2', 'lag3', 'lag4', 'lag5',\n",
       "       'lag6', 'lag7', 'Friday', 'Monday', 'Saturday', 'Sunday',\n",
       "       'Thursday', 'Tuesday', 'Wednesday', 'hour__0', 'hour__1',\n",
       "       'hour__2', 'hour__3', 'hour__4', 'hour__5', 'hour__6', 'hour__7',\n",
       "       'hour__8', 'hour__9', 'hour__10', 'hour__11', 'hour__12',\n",
       "       'hour__13', 'hour__14', 'hour__15', 'hour__16', 'hour__17',\n",
       "       'hour__18', 'hour__19', 'hour__20', 'hour__21', 'hour__22',\n",
       "       'hour__23', 0, 20, 40, 'ch_holidays', 'index', 'pressure',\n",
       "       'sea_pressure', 'wind_direction', 'wind_speed', 'temperature',\n",
       "       'rel_humidity', 'precipitation', 'inlink_cross_count',\n",
       "       'outlink_cross_count', 'length', 'link_count', 'lane1_length',\n",
       "       'lane1_count', 'lane2_length', 'lane2_count', 'lane3_length',\n",
       "       'lane3_count', 'lane4_length', 'lane4_count'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t_5.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 63)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_t_5_dup.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
